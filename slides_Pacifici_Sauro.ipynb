{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> Python Project </center>\n",
    "\n",
    "## <center> Graphs building and analysis </center>\n",
    "\n",
    "### Authors: \n",
    "#### Martina Pacifici (7005686) and Federica Sauro Graziano (6360850)\n",
    "\n",
    "![title](https://www.google.com/search?q=logo+unifi&tbm=isch&source=iu&ictx=1&fir=W8Mt4YB506ck_M%252C5XB63tEAzK6DAM%252C_&vet=1&usg=AI4_-kQz_tlNndA-4rsdgXOz5pF2GUJFow&sa=X&ved=2ahUKEwjoi_2UusXqAhXaMMAKHcKwD2UQ9QEwAHoECAoQFA&biw=1366&bih=576#imgrc=aYnSu_DgUmkYuM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"C:\\\\Users\\\\feder\\\\OneDrive\\\\Documenti\\\\Fede\\\\University\\\\STAT_M1\\\\AlgoritmiPython\\\\project\\\\dpc-covid19-ita-province.json\") as f:\n",
    "\n",
    "         d = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "corona = pd.DataFrame(d)\n",
    "corona = corona.drop(corona[corona.lat==0.0].index)\n",
    "corona.reset_index(inplace=True)\n",
    "df = corona[0:107]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> Graph bulding </center>\n",
    "\n",
    "After having converted our dataset in a pandas DataFrame, we extract only all the 107 provinces at a particular moment of time (we didn't care about the date). \n",
    "In this way we have all the italian provinces with the spatial information of latitude and longitude (in decimal degree) that allow us to to build the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The graph will be a nextwork of provinces called 'P' in which each node corresponds to a city.\n",
    "Two cities a and b are connected by an edge if they are close in 0.8 decimal degree (that is: if x,y is the position of a, then b is in position z,w with z in [x-d,x+d] and w in [y-d, y+d], with d=0.8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "NetworkX  is a python package useful for the implementation, manipulation, and study of a standard, dynamics and complex graph structure.\n",
    "\n",
    "First we use networkx to create all the nodes, that are the provinces of a general graph 'G', through the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from(corona.sigla_provincia)\n",
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### First implementation (not efficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "for i in range(len(df)):\n",
    "    for j in range(len(df)):\n",
    "        if (i != j) & (abs(df.lat[i]-df.lat[j]) <= 0.8) & (abs(df.long[i]-df.long[j]) <= 0.8):\n",
    "            G.add_edge(df.sigla_provincia[i],df.sigla_provincia[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our first implementation uses two for cicles to find the provinces close (in terms of latitude and longitude) to every node and finally add an edge to the graph 'G' if the proximity requirement is respected.\n",
    "\n",
    "This algorithm costs **O($n^2$)**, so we tried to find a better solution to add edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Second implementation (more efficient)\n",
    "\n",
    "First we need to sort the DataFrame. We created two new sorted DataFrame one respect to longitude and the other respect to latitude. \n",
    "\n",
    "To do so, we chose the Mergesort method, which seemed to be the most efficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sorted_dfx = df.sort_values(by = 'long', kind = 'mergesort')\n",
    "sorted_dfx.reset_index(inplace = True)\n",
    "sorted_dfy = df.sort_values(by = 'lat', kind ='mergesort')\n",
    "sorted_dfy.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is important in order to use the binarySearch function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def binarySearch(alist, item, prov, d):\n",
    "    first = 0\n",
    "    last = len(alist)-1\n",
    "    found = False\n",
    "    while first<=last and not found:\n",
    "        midpoint = (first + last)//2\n",
    "        if alist[midpoint]==float(item):\n",
    "            found = True\n",
    "            return list(prov[(alist>=float(alist[midpoint]-d)) & (alist<=float(alist[midpoint]+d))])\n",
    "        else:\n",
    "            if float(item) < alist[midpoint]:\n",
    "                last = midpoint-1\n",
    "            else:\n",
    "                first = midpoint+1\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here the function inter_city will help us taking the interesection between the closest cities of a node in respect to both latitudine and longitude.\n",
    "\n",
    "We used a dictionary to collect the cities to have a more efficient function. In the worst case it takes **O(n)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def inter_city(A,B,elem):\n",
    "    C = {}\n",
    "    for el in B:\n",
    "        if el!=elem and el not in C and el in A:\n",
    "            C[el]=0\n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Graph P\n",
    "\n",
    "Finally we can implement our provinces graph:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "P = nx.Graph()\n",
    "P.add_nodes_from(sorted_dfx.sigla_provincia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455 ms ± 55 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for el in sorted_dfx.sigla_provincia:\n",
    "    lista_legami_x = binarySearch(sorted_dfx.long, sorted_dfx.long[sorted_dfx.sigla_provincia==el], \n",
    "                                  sorted_dfx.sigla_provincia, 0.8)\n",
    "    lista_legami_y = binarySearch(sorted_dfy.lat, sorted_dfy.lat[sorted_dfy.sigla_provincia==el], \n",
    "                                  sorted_dfy.sigla_provincia, 0.8)\n",
    "    lst_x = {j:0 for j in lista_legami_x}\n",
    "    lst_y = {j:0 for j in lista_legami_y}\n",
    "    città_vicine = inter_city(lst_x, lst_y, el)\n",
    "    edge_city = []\n",
    "    for j in città_vicine:\n",
    "        edge_city.append((el, j))\n",
    "    P.add_edges_from(edge_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'P' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-65b16e5f9205>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_of_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lightpink'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'P' is not defined"
     ]
    }
   ],
   "source": [
    "P.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "nx.draw(P, with_labels=True, node_color='lightpink')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can observe that this node is made by four different components:\n",
    "\n",
    "The province of Trapani is an isolated node;\n",
    "All the provinces of Sardinia make a single component;\n",
    "All the provinces of Calabria and Sicily regions (except from Trapani) make a single component;\n",
    "The rest of Italy's provinces are connected by edges. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Graph R\n",
    "\n",
    "We now use our second implemention to build a larger graph R. \n",
    "\n",
    "First we generate 2000 pairs of double (x,y) with x in [30,50) and y in [10,20], which will correspond to fictitious provinces with their longitude (x) and latitude (y), and insert them in a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "latit = [] \n",
    "longit = []  \n",
    "nodes = [] \n",
    "for i in range(2000):\n",
    "    latit.append(random.uniform(30,50))\n",
    "    longit.append(random.uniform(10,20))\n",
    "    nodes.append(str(i))\n",
    "    \n",
    "dataRandom = {'province': nodes,\n",
    "              'longitudine' : longit,\n",
    "              'latitudine' : latit}    \n",
    "\n",
    "dataR = pd.DataFrame(dataRandom, columns = ['province', 'longitudine', 'latitudine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Again, after building a new graph R, we create new DataFrames sorting dataR once for x and once for y: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "R = nx.Graph()\n",
    "R.add_nodes_from(dataR.province)\n",
    "R.number_of_nodes()\n",
    "\n",
    "sort_dataRx= dataR.sort_values(by = 'longitudine', kind = 'mergesort')\n",
    "sort_dataRx.reset_index(inplace = True)\n",
    "sort_dataRy = dataR.sort_values(by = 'latitudine', kind ='mergesort')\n",
    "sort_dataRy.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we add edges to the graph R for the provinces that has both latitude and longitude within 0.08 degree from the ones of the node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "for el in sort_dataRx.province:\n",
    "    legami_x = binarySearch(sort_dataRx.longitudine, sort_dataRx.longitudine[sort_dataRx.province==el], sort_dataRx.province, 0.08)\n",
    "    legami_y = binarySearch(sort_dataRy.latitudine, sort_dataRy.latitudine[sort_dataRy.province==el], sort_dataRy.province, 0.08)\n",
    "    lst_x = {j:0 for j in lista_legami_x}\n",
    "    lst_y = {j:0 for j in lista_legami_y}\n",
    "    città_vicine = inter_city(lst_x, lst_y, el)\n",
    "    edge_city = []\n",
    "    for j in città_vicine:\n",
    "        edge_city.append((el, j))\n",
    "    R.add_edges_from(edge_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "R.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Here we show how the graph R appears: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nx.draw(R, node_color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Weighted Graph\n",
    "\n",
    "Now we weight both the graph P and R for the distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "for el in sorted_dfx.sigla_provincia:\n",
    "    lista_legami_x = binarySearch(sorted_dfx.long, sorted_dfx.long[sorted_dfx.sigla_provincia==el], sorted_dfx.sigla_provincia, 0.8)\n",
    "    lista_legami_y = binarySearch(sorted_dfy.lat, sorted_dfy.lat[sorted_dfy.sigla_provincia==el], sorted_dfy.sigla_provincia, 0.8)\n",
    "    lst_x = {j:0 for j in lista_legami_x}\n",
    "    lst_y = {j:0 for j in lista_legami_y}\n",
    "    città_vicine = inter_city(lst_x, lst_y, el)\n",
    "    edge_city = []\n",
    "    for j in città_vicine:\n",
    "        distanza_x = (float(sorted_dfx.long[sorted_dfx.sigla_provincia==el])-float(sorted_dfx.long[sorted_dfx.sigla_provincia==j]))**2\n",
    "        distanza_y = (float(sorted_dfy.lat[sorted_dfy.sigla_provincia==el])-float(sorted_dfy.lat[sorted_dfy.sigla_provincia==j]))**2\n",
    "        distanza = math.sqrt(distanza_x+distanza_y)\n",
    "        edge_city.append((el, j, distanza))\n",
    "    P.add_weighted_edges_from(edge_city)\n",
    "               \n",
    "\n",
    "P.number_of_edges()\n",
    "nx.draw(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for el in sort_dataRx.province:\n",
    "    legami_x = binarySearch(sort_dataRx.longitudine, sort_dataRx.longitudine[sort_dataRx.province==el], sort_dataRx.province, 0.08)\n",
    "    legami_y = binarySearch(sort_dataRy.latitudine, sort_dataRy.latitudine[sort_dataRy.province==el], sort_dataRy.province, 0.08)\n",
    "    lst_x = {j:0 for j in lista_legami_x}\n",
    "    lst_y = {j:0 for j in lista_legami_y}\n",
    "    città_vicine = inter_city(lst_x, lst_y, el)\n",
    "    edge_city = []\n",
    "    for j in città_vicine:\n",
    "        distanza_x = ((sort_dataRx.longitudine[sort_dataRx.province==el])-(sort_dataRx.longitudine[sort_dataRx.province==j]))**2\n",
    "        distanza_y = ((sort_dataRy.latitudine[sort_dataRy.province==el])-(sort_dataRy.latitudine[sort_dataRy.province==j]))**2\n",
    "        distanza = math.sqrt(distanza_x+distanza_y)\n",
    "        edge_city.append((el, j, distanza))\n",
    "    R.add_weighted_edges_from(edge_city)\n",
    " \n",
    "R.number_of_edges()\n",
    "nx.draw(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Bellman Ford\n",
    "\n",
    "We decided to use Bellman Ford algorithm in order to get the shortest path from a single source vertex to all the others part of the same weighted graph. \n",
    "\n",
    "Bellman-Ford algorithm proceeds by relaxation, in which approximations to the correct distance are replaced by better ones until they eventually reach the solution.\n",
    "\n",
    "It is comparable with Dijkstra's algorithm for how they work. In both algorithms, the approximate distance to each vertex is always an overestimate of the true distance, and is replaced by the minimum of its old value and the length of a newly found path.\n",
    "\n",
    "Even if Bellman-Ford algorithm is slower than Dijkstra's, it is able to deal with graphs in which some of the edge weights are negative numbers. For sure this is not our case because the weights of our graphs are geographical distances and they can never be negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here we analyze the three steps of the algorithm. \n",
    "\n",
    "We start it inizializing the distance to the source vertex to 0 and all the other nodes to infinity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def bell_ford(graph, source):\n",
    "    \n",
    "    #inizialization\n",
    "    dist = {}\n",
    "    pred = {}\n",
    "    \n",
    "    for v in graph.node():\n",
    "        dist[v] = math.inf\n",
    "        pred[v] = None\n",
    "    \n",
    "    dist[source] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "After inizializing we proceed with the relaxation: for all edges, if the distance to the destination can be shortened by taking the edge, the distance is updated to the new lower value.\n",
    "\n",
    "At each iteration i that the edges are scanned, the algorithm finds all shortest paths of at most length i edges (and possibly some paths longer than i edges). \n",
    "\n",
    "If the graph is connected we get at most |V|-1 edges in our path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    " #relaxation\n",
    "    for i in range(len(graph)-1): #Run this until is converges\n",
    "        for u in graph:\n",
    "            for v in graph[u]: #For each neighbour of u\n",
    "                if dist[v] > dist[u] + graph[u][v]['weight']:\n",
    "                    # Record this lower distance\n",
    "                    dist[v]  = dist[u] + graph[u][v]['weight']\n",
    "                    pred[v] = u\n",
    "                if dist[u] > dist[v] + graph[u][v]['weight']:\n",
    "                    # Record this lower distance\n",
    "                    dist[u]  = dist[v] + graph[u][v]['weight']\n",
    "                    pred[u] = v\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The last step of the algorithm is needed to detect the presence of negative-weight cycle. In fact, without this part, if the algorithm finds a nevative-weight cycle, it would enter in an Infinite Loop. \n",
    "\n",
    "Thanks to this third step if it happens to find one negative-weight cycle the algorithm will return an AssertionError, while if there aren't it will go on returning the shortest path from the source vertex to all the others.\n",
    "\n",
    "Finally the algorithm returns the shortest path in terms of distance and the predecessor to the final node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#check for negative-weight cycles\n",
    "    for u in graph:\n",
    "        for v in graph[u]:\n",
    "            assert dist[v] <= dist[u] + graph[u][v]['weight']\n",
    "    return dist, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here we show some results for both the weighted graph P and R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'P' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-24bed642f25b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbell_ford\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'OR'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbell_ford\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TP'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbell_ford\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'KR'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbell_ford\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'FI'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#list(nx.connected_components(P))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'P' is not defined"
     ]
    }
   ],
   "source": [
    "bell_ford(P, 'OR')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bell_ford(P, 'TP')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bell_ford(P, 'FI')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bell_ford(P, 'KR')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bell_ford(R, ('2'))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Both graphs P and R are not connected, so the path from a source vertex of a specific compontent to other nodes that aren't part of that component is set to Infinity. \n",
    "\n",
    "In fact we can see that the province of Trapani, which builds itself a component, has all the paths set to infinity except for the one with itself, which is 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Closeness Centrality\n",
    "\n",
    "In a connected graph, the closeness centrality of a node is a measure of centrality in a network, calculated as the reciprocal of the sum of the length of the shortest paths between the node and all other nodes in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The closeness centrality of a node v in a graph V is defined as:\n",
    "\n",
    "$$c(v) =\\frac {n−1}{f(v)}$$\n",
    "\n",
    "where n are the number of nodes and f(v) is the farness of a node v equal to $\\Sigma_{w \\in V}d(v,w)$, that is the sum of the distances between the two vertices v and w."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since we don't have a connected graph we use its variance in which, instead of the reciprocal of the sum, we sum the reciprocal of the distances (infact, when a distance is infinite we'll have to sum $\\frac{1}{\\infty}=0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We first define a closeness centrality algorithm based on the shortest paths computed with **Bellman-Ford**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def closeness(graph, u):\n",
    "    dizy_dist = bell_ford(graph, u)[0]\n",
    "    close = 0.0\n",
    "    for key in dizy_dist:\n",
    "        if dizy_dist[key] != 0 and dizy_dist[key] != math.inf:\n",
    "            close = close + 1/dizy_dist[key]\n",
    "    return close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here some results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "closeness(P,'TP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "closeness(P,'FI') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For a better interpretation we now use an algorithm which returns the **normalized** closeness index based on **Bellman-Ford** distance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def closeness_norm_dist(graph, u):\n",
    "    dizy_dist = bell_ford(graph, u)[0]\n",
    "    total = 0\n",
    "    n_short_path = 0\n",
    "    cc= 0.0\n",
    "    for key in dizy_dist:\n",
    "        if dizy_dist[key] != 0 and dizy_dist[key] != math.inf:\n",
    "            total = total + dizy_dist[key]\n",
    "            n_short_path+=1\n",
    "    if total > 0.0 and len(graph)>1:\n",
    "        s = (n_short_path)/(len(graph)-1)\n",
    "        cc = ((n_short_path)/total)*s\n",
    "    return cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We now show the closeness centrality normalized index again for Trapani and Florencia provinces: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "closeness_norm_dist(P,'TP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "closeness_norm_dist(P,'FI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Furthermore we implemented the same **normalized** closeness algorithm but using the **shortest path length** of *NetworkX* (without specificating weights) instead of Bellman-Ford:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def closeness_norm_short(graph, u):\n",
    "    dizy_dist = nx.shortest_path_length(graph, u)\n",
    "    total = 0\n",
    "    n_short_path = 0\n",
    "    cc = 0.0\n",
    "    for key in dizy_dist:\n",
    "        if dizy_dist[key] != 0 and dizy_dist[key] != math.inf:\n",
    "            total = total + dizy_dist[key]\n",
    "            n_short_path+=1\n",
    "    if total > 0.0 and len(graph)>1:\n",
    "        s = (n_short_path)/(len(graph)-1)\n",
    "        cc = ((n_short_path)/total)*s\n",
    "    return cc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "closeness_norm_short(P,'TP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "closeness_norm_short(P,'FI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "closeness_norm_short(R,'2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally through the following algorithm we'll get the **most central node** of a graph based on our second closeness algorithm (which uses Bellman-Ford distance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def massimaClosy(graph):\n",
    "    maximum = 0.0\n",
    "    city = ''\n",
    "    for v in graph.nodes():\n",
    "        closy = closeness_norm_dist(graph,v)\n",
    "        if closy >= maximum:\n",
    "            maximum = closy\n",
    "            city = v\n",
    "    return city, maximum\n",
    "\n",
    "massimaClosy(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Or, alternatively, in a more efficient way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_key(val, my_dict): \n",
    "    for key, value in my_dict.items(): \n",
    "         if val == value: \n",
    "             return key \n",
    "    return \"key doesn't exist\"\n",
    "\n",
    "dist_max = max(list(nx.closeness_centrality(P,distance = 'weight').values()))\n",
    "get_key(dist_max,nx.closeness_centrality(P,distance = 'weight'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank you for your attention!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
